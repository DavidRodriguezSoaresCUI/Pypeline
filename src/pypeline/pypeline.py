"""
the pypeline
============

The pypeline is the collective designation for 3 artifacts:

- the workers
- the orchestrators (one per worker)
- the processors (across all workers)
- the activities (single repository for all workers)

Together they handle complex workflows and do actual work reliably (and in a
distributed fashion with multiple workers).


on multiple workers
===================

When multiple workers operate on the same activities repository, there are inherent
complications. Mostly, if more than one worker accepts activities of a given type,
there must be a process by which the activity is attributed to a single worker. Here
we use a naive solution based on renaming the file and checking whether that action
was successful.


the state
=========

The processors are entirely stateless and the activities are entirely stateful. The
orchestrator is stateful in the sense that it accesses a configuration (shared by all
workers) and handles activities which are stateful. Therefore, "the state of the
pypeline" refers to the shared activities and orchestrator configuration.


todo
====

- deal with processor log messages
- deal with processing timeout
"""

import logging
import string
import time
from datetime import datetime
from pathlib import Path
from traceback import format_exception
from typing import Callable, Dict, List

from DRSlib.multiprocessing import SimpleMultiProcessing
from DRSlib.path_tools import ensure_dir_exists
from DRSlib.stream import Collector, Stream

from .activity import (
    Activity,
    ActivityState,
    ExitState,
    ExitStatus,
)
from .processors import Processor, ActivityArchivalProcessor
from .properties_manager import PropertiesManager
from .rule_engine import (
    ACTIVITY_BOOTSTRAP_META_HEADER,
    ACTIVITY_PROCESSING_CONFIG_FILE_NAME,
    ACTIVITY_PROCESSING_CONFIG_HEADER,
    ACTIVITY_PROCESSING_META_HEADER,
    BOOTSTRAP_CONFIG_FILE_NAME,
    BOOTSTRAP_CONFIG_HEADER,
    LABEL_ACTIVITY_DATA,
    LABEL_ACTIVITY_TYPE,
    LABEL_BOOTSTRAP_RULE,
    LABEL_FIRE_ON_FIRST_CYCLE,
    LABEL_PARELLEL_PROCESSES,
    LABEL_WORKER_ID,
    NoRuleMatchError,
    RuleEngine,
    RuleEngineTypes,
)
from .timed_execution_rule import TimedExecutionRule
from .utils import (
    LOG_FORMAT_WITH_TIME,
    LOG_SEPARATOR,
    PYPELINE_LOGGER,
    FileDefinedValue,
    Singleton,
    add_file_handler,
    change_formatters,
    full_exception,
    make_JSON_string_safe,
    random_base32,
    remove_file_handlers,
)

LOG = logging.getLogger(PYPELINE_LOGGER)

DEFAULT_ORCHESTRATOR_LOOP_DELAY_S = 60
PROCESSOR_LOG_FORMAT = "[%(asctime)s][%(levelname)s][{}] %(message)s"
ALLOWED_WORKER_ID_CHARACTERS = string.ascii_letters + string.digits + "-_"
BOOTSTRAP_ACTIVITIES_SPECIAL_ACTIVITY_TYPE = "@bootstrap_activities"
PROCESSOR_ERROR_ID = "$P_ERROR$"


class TrackedActivity:
    """An Orchestrator can track an activity but not OWN it"""

    activity_file: Path
    """path of the tracked activity"""
    activity_key: str
    """Unique key for tracked activity, needed for resynchronization"""
    state_timestamp: int
    """Timestamp at which the activity begun to be tracked under this state"""
    attached_files: list[Path]
    """Extra files (like log files) generated by the activity, that need to be moved with the activity file"""

    def __init__(self, activity_file: Path) -> None:
        self.activity_file = activity_file
        self.activity_key = Activity.from_file(activity_file).unique_key
        self.state_timestamp = int(time.time())
        self.attached_files = []
        LOG.info("Starting to track activity %s", Activity.get_id(activity_file.name))

    def __state(self) -> ActivityState:
        """Return activity state (no resynchronisation)"""
        return ActivityState[self.activity_file.parent.name]

    @property
    def state(self) -> ActivityState:
        """Return tracked activity state"""
        self.resynchronise()
        return self.__state()

    @property
    def type(self) -> str:
        """Return tracked activity state"""
        return Activity.get_type(self.activity_file.name)

    @property
    def activity_id(self) -> str:
        """Return tracked activity state"""
        return Activity.get_id(self.activity_file.name)

    def __retry_count(self) -> int:
        """Return activity retry count (no resynchronisation)"""
        return Activity.get_retry_count(self.activity_file.name)

    @property
    def retry_count(self) -> int:
        """Return the retry count for current activity"""
        self.resynchronise()
        return self.__retry_count()

    @property
    def still_exists(self) -> int:
        """Return whether activity exists, False if it was removed"""
        try:
            self.resynchronise()
        except FileNotFoundError:
            return False
        return True

    def resynchronise(self) -> None:
        """Resynchronises with activity files"""
        if (
            self.activity_file.is_file()
            and self.activity_file.parent != ActivityState.ERROR.name
        ):
            return

        LOG.info("Resynchronising activity %s", self.activity_file.name)
        last_known_state, last_retry_count = self.__state(), self.__retry_count()
        activity_root_dir = self.activity_file.parent.parent

        # Find lost activity
        candidate_activities = list(
            activity_root_dir.rglob(self.activity_key + "*.json")
        )
        if len(candidate_activities) == 0:
            raise FileNotFoundError(f"Lost track of activity {self.activity_id}")
        self.activity_file = max(
            candidate_activities, key=lambda _path: Activity.get_retry_count(_path.name)
        )

        # Update state timestamp if necessary
        if self.__state() != last_known_state:
            _now = int(time.time())
            change = (
                f"change of state ({last_known_state} -> {self.__state()})"
                if self.__retry_count() == last_retry_count
                else f"retry ({last_retry_count} -> {self.__retry_count()})"
            )
            LOG.info(
                "Activity tracking: resynchronised with activity %s after %s (time elapsed since last change: %ss)",
                self.activity_id,
                change,
                _now - self.state_timestamp,
            )
            self.state_timestamp = _now

        # reattach associated files
        self.attached_files = [
            p
            for p in self.activity_file.parent.glob(self.activity_file.stem + "*")
            if p != self.activity_file
        ]

    def set_retry(self) -> None:
        """Increment retry count and rename file accordingly"""
        self.resynchronise()
        activity = Activity.from_file(self.activity_file)
        activity.retries += 1
        self.activity_file = self.activity_file.rename(
            self.activity_file.parent / activity.file_name()
        )
        self.state_timestamp = int(time.time())

    def attach_file(self, file_to_attach: Path) -> None:
        """Adds a file to attached files so it can be moved with the activity file"""
        self.resynchronise()
        LOG.debug(
            "File %s attached to activity %s",
            file_to_attach.name,
            self.activity_file.name,
        )
        self.attached_files.append(file_to_attach)

    def change_state(
        self,
        destination_state: ActivityState,
        activity_dir_resolver: Callable[[ActivityState], Path],
    ) -> Path | None:
        """This operation requires taking ownership of this activity but may fail (return None)"""
        self.resynchronise()

        destination_dir = activity_dir_resolver(destination_state)
        target_file = destination_dir / self.activity_file.name

        try:
            self.activity_file = self.activity_file.rename(target_file)
            self.attached_files = [
                f.rename(destination_dir / f.name) for f in self.attached_files
            ]
        except FileNotFoundError:
            # ownership and state change failed
            return None

        # ownership and state change succeeded
        self.state_timestamp = int(time.time())
        return target_file

    def remove(self) -> None:
        """Removes activity and related file, typically the activity is in a final state but nothing was done"""
        self.resynchronise()

        LOG.info(
            "Removing all files related to activity %s (%s)",
            self.activity_id,
            self.type,
        )
        for _file in [self.activity_file] + self.attached_files:
            _file.unlink(missing_ok=True)


class ActivityBootstrapRule:
    """Handles the logic related to parsing an activity boostrap rule"""

    activity_type: str
    """Activity type"""
    bootstrap_execution: TimedExecutionRule
    """Rule for when to bootstrap the activity"""
    activity_file_contents: str
    """Contents of the activity file"""
    fire_on_next_cycle: bool
    """Used to not to create an activity on the very first call"""

    def __init__(
        self,
        activity_type: str,
        bootstrap_rule: str,
        activity_file_contents: str | None = None,
        fire_on_first_cycle: bool = True,
    ) -> None:
        self.activity_type = activity_type
        _rule = TimedExecutionRule.from_expression(bootstrap_rule)
        if _rule is None:
            raise ValueError(f"Can't decode rule '{bootstrap_rule}'")
        self.bootstrap_execution = _rule
        self.activity_file_contents = (
            "" if activity_file_contents is None else activity_file_contents
        )
        self.fire_on_next_cycle = fire_on_first_cycle

    def apply(self, current_time: datetime, reserved_ids: set[str]) -> Activity | None:
        """If appropriate, returns a new activity to be created"""
        if self.bootstrap_execution.is_up(current_time):
            self.bootstrap_execution.mark_executed(current_time)
            LOG.debug(
                "ActivityBootstrapRule.apply: execution for type %s; fire_on_next_cycle=%s",
                self.activity_type,
                self.fire_on_next_cycle,
            )

            while (activity_id := random_base32(3)) in reserved_ids:
                continue

            if self.fire_on_next_cycle:
                return Activity(
                    activity_type=self.activity_type,
                    creation_time=current_time,
                    activity_id=activity_id,
                    retries=0,
                    state=ActivityState.TO_BE_PROCESSED,
                    data=self.activity_file_contents,
                )
            self.fire_on_next_cycle = True
        return None


class ProcessorRunner(metaclass=Singleton):
    """This class is dedicated at running subprocesses. For technical reasons this was necessary."""

    def __init__(self) -> None:
        pass

    def process_activity(
        self,
        tracked_activity: TrackedActivity,
        activity_dirs: Dict[ActivityState, Path],
        processor: Processor,
        worker_id: str,
        properties_manager_setup: list[Path],
    ) -> str | None:
        """Called in a subprocess to run a Processor on an Activity"""

        if PropertiesManager.get_instance() is None:
            LOG.info("Setting properties manager in processor execution context")
            PropertiesManager(properties_manager_setup)

        start_datetime = datetime.fromtimestamp(int(time.time()))
        start_datetime_readable = start_datetime.isoformat()
        activity_id = Activity.get_id(tracked_activity.activity_file.name)
        activity_type = Activity.get_type(tracked_activity.activity_file.name)

        # change activity status
        activity_status_dir_resolver: Callable[
            [ActivityState], Path
        ] = lambda activity_state: activity_dirs[activity_state]
        in_progress_activity_file = tracked_activity.change_state(
            ActivityState.IN_PROGRESS, activity_status_dir_resolver
        )
        if in_progress_activity_file is None:
            LOG.error(
                "Failed to transition activity %s to state IN_PROGESS; aborting",
                activity_id,
            )
            return None

        activity = Activity.from_file(in_progress_activity_file)

        # Build new logger for this execution
        logfile = in_progress_activity_file.with_suffix(
            f".{start_datetime_readable.replace(':', '-')}.log"
        )
        tracked_activity.attach_file(logfile)
        log = logging.getLogger(activity_type + activity_id)
        log.setLevel(logging.DEBUG)
        log.handlers.clear()
        add_file_handler(log, logfile, logging.DEBUG)

        proc_name = processor.__qualname__  # type: ignore[attr-defined]
        log.info(
            "Start processing activity %s (%s) at %s using processor %s",
            activity_id,
            activity_type,
            start_datetime_readable,
            proc_name,
        )

        # Some last-second setup
        log.info(LOG_SEPARATOR)
        change_formatters(log, PROCESSOR_LOG_FORMAT.format(proc_name))
        processor.set_property_prefix(worker_id)

        # Processor exection and exception handling
        proc_ex: str | None = None
        try:
            exit_state = processor.execute(activity, log)
        except Exception as e:
            log.error("Processor execution was interrupted by the following exception")
            log.exception(e)
            exit_state = ExitState.error(str(e))
            proc_ex = full_exception(e)

        # Post-execution actions
        end_datetime = datetime.fromtimestamp(int(time.time()))
        change_formatters(log, LOG_FORMAT_WITH_TIME)
        log.info(LOG_SEPARATOR)
        if exit_state is None:
            raise ValueError(f"Processor {proc_name} did not return an exit state")

        log.info(
            "End processing activity at %s (time elapsed: %s)",
            end_datetime.isoformat(),
            end_datetime - start_datetime,
        )

        _logger = log.info if exit_state.status is ExitStatus.SUCCESS else log.warning
        _logger("Execution of activity ended with status %s", exit_state)

        # Remove file handler so log files can be moved
        remove_file_handlers(log)

        if exit_state.remove_activity:
            tracked_activity.remove()
        else:
            if exit_state.status == ExitStatus.ERROR_RETRY:
                tracked_activity.set_retry()
            tracked_activity.change_state(
                exit_state.next_activity_status, activity_status_dir_resolver
            )
        LOG.info("Post-execution actions done. The process will exit now")

        return proc_ex

    def process_activities(
        self, arguments: list[Dict], parallel_instances: int
    ) -> List[str | None]:
        """Runs activities in child processes and returns their return value"""
        # Fill values from Orchestrator
        return SimpleMultiProcessing.bulk_processing(
            self.process_activity,
            arguments,
            parallel_instances,
        )


class Orchestrator(metaclass=Singleton):
    """
    Each "worker" runs a single instance of the orchestrator, that :

    - has access to set of processors
    - can see the activities
    - executes processors on activities
    - makes the status of activities progress (by moving them)
    - configuration in a table file with rules for:
      - bootstrap activity creation
      - activity retention time
      - activity lock retention time
    """

    root_dir: Path
    """Root directory containing configuration and activity files"""
    processor_by_handled_activity_type: dict[str, Processor]
    """Map of processors by the activity type they handle"""
    activity_processing_configuration: FileDefinedValue[RuleEngine]
    """Configuration on activity bootstrapping"""
    tracked_activities: dict[str, TrackedActivity]
    """Orchestrator keeps track of activities it wants to process or is processing"""
    worker_id: str
    """Unique identifier for this worker"""
    activity_bootstrap_rules: FileDefinedValue[list[ActivityBootstrapRule]]
    """Rules governing activities to create"""
    # timer_manager: TimerManager
    processor_runner: ProcessorRunner
    properties_manager: PropertiesManager

    # Properties used
    ROOT_PPTY = ["Orchestrator"]
    SLEEP_SECONDS_PPTY = ROOT_PPTY + ["sleep-seconds"]
    STOP_NOW_PPTY = ROOT_PPTY + ["stop-now"]
    ON_EXCEPTION_ACTIVITY_TYPE_PPTY = ROOT_PPTY + ["on-activity-error", "activity-type"]
    ON_EXCEPTION_ACTIVITY_CONTENT_PPTY = ROOT_PPTY + [
        "on-activity-error",
        "activity-content",
    ]

    def __init__(
        self, processors: list[Processor], root_dir: Path, worker_id: str
    ) -> None:
        self.root_dir = root_dir
        ensure_dir_exists(root_dir)

        self.properties_manager = PropertiesManager(
            property_files=list(self.root_dir.glob("*.properties"))
        )

        self.worker_id = worker_id
        if len(worker_id) < 3:
            raise ValueError(
                "worker_id too short; please make it at lease 3 characters"
            )
        illegal_characters = set(
            c for c in worker_id if c not in ALLOWED_WORKER_ID_CHARACTERS
        )
        if illegal_characters:
            raise ValueError(
                f"Illegal characters found in worker ID '{worker_id}': {illegal_characters}"
            )

        add_file_handler(LOG, root_dir / f"worker.{worker_id}.log")

        if ActivityArchivalProcessor not in processors:
            processors.append(ActivityArchivalProcessor)  # type: ignore[arg-type]
        for p in processors:
            p.validate()
        self.processor_by_handled_activity_type = {
            p.get_input_activity_type(): p for p in processors
        }

        # self.timer_manager = TimerManager()
        self.processor_runner = ProcessorRunner()
        self.tracked_activities = {}
        self.activity_bootstrap_rules = FileDefinedValue[list[ActivityBootstrapRule]](
            self.root_dir / BOOTSTRAP_CONFIG_FILE_NAME, self.setup_bootstraps()
        )
        if worker_id is None:
            LOG.warning("Worker id is not set")

        self.activity_processing_configuration = FileDefinedValue[RuleEngine](
            root_dir / ACTIVITY_PROCESSING_CONFIG_FILE_NAME,
            self.setup_activity_processing_configuration(),
        )

    @property
    def handled_activity_types(self) -> set[str]:
        """Returns a copy of handled activity types set"""
        return set(self.processor_by_handled_activity_type.keys())

    def activity_dir(self, activity_state: ActivityState) -> Path:
        """Returns path of directory containing activities of corresponding state"""
        _path = self.root_dir / activity_state.name
        ensure_dir_exists(_path)
        return _path

    @property
    def activity_dirs(self) -> Dict[ActivityState, Path]:
        """Returns all activity directories by state"""
        return {_as: self.activity_dir(_as) for _as in ActivityState}

    def create_activities(
        self,
        activity_type: str,
        activities_data: list[str],
        processor: Processor | None = None,
    ) -> None:
        """Create a list of activities. This is meant for processors to call when producing new activities"""

        if not isinstance(activities_data, list):
            raise ValueError(
                f"Expected 'activities_data' to be a list, got {type(activities_data)} ({activities_data})"
            )
        check_activity_type_decared = True

        # Case: error caught by processor wrapper
        if activity_type is PROCESSOR_ERROR_ID:
            on_exception_activity_type = self.properties_manager.get_string(
                self, self.ON_EXCEPTION_ACTIVITY_TYPE_PPTY
            )
            if on_exception_activity_type not in self.handled_activity_types:
                LOG.warning(
                    "Processor %s raised an exception but exception processing is not set up",
                    self.processor_by_handled_activity_type(activity_type),
                )
                return
            activity_type = on_exception_activity_type
            check_activity_type_decared = False

        # Argument processor may be omitted if it is certain activity type is handled
        if processor is None:
            processor = self.processor_by_handled_activity_type[activity_type]

        if (
            check_activity_type_decared
            and activity_type not in processor.get_output_activity_types()
        ):
            raise TypeError(
                f"Activity type {activity_type} is undeclared in {processor.__qualname__}"  # type: ignore[attr-defined]
            )

        LOG.info(
            "Creating %s activities of type %s for processor %s",
            len(activities_data),
            activity_type,
            processor.__class__.__name__,
        )
        for activity_data in activities_data:
            Activity(
                activity_type=activity_type,
                creation_time=datetime.now(),
                activity_id=random_base32(3),
                retries=0,
                state=ActivityState.TO_BE_PROCESSED,
                data=activity_data,
            ).write_file(self.root_dir)

    def get_untracked_activities(
        self, selected_state: ActivityState
    ) -> dict[str, Path]:
        """Returns untracked activities of selected state"""
        return {
            activity_id: f
            for f in self.activity_dir(selected_state).glob("activity.*.json")
            if (activity_id := Activity.get_id(f.name)) not in self.tracked_activities
            or self.tracked_activities[activity_id].state is not selected_state
        }

    def get_tracked_activities(
        self, selected_state: ActivityState
    ) -> list[TrackedActivity]:
        """Returns tracked activities of selected state"""
        res = []
        for k, t_a in dict(self.tracked_activities).items():
            try:
                if t_a.state is selected_state:
                    res.append(t_a)
            except FileNotFoundError:
                del self.tracked_activities[k]
        return res

    def allowed_parallel_processes(self, activity_type: str) -> int:
        """Fetches allowed parallel processes from configuration"""
        _criteria: dict[str, RuleEngineTypes] = {LABEL_ACTIVITY_TYPE: activity_type}
        if self.worker_id is not None:
            _criteria[LABEL_WORKER_ID] = self.worker_id
        conf: RuleEngine = self.activity_processing_configuration.get()
        res = conf.get_single_mapping(
            criteria=_criteria,
            value=LABEL_PARELLEL_PROCESSES,
        )
        if isinstance(res, int):
            return res
        raise ValueError(
            f"Expected int value, found {type(res)} when fetching value for {LABEL_PARELLEL_PROCESSES} from {conf.configuration_file.stem} with criteria {_criteria}"
        )

    def process_tbp_activities(self) -> None:
        """Refresh the list of activities that may be processed next and
        kickstart their execution
        """

        # find new TBP activities
        _new_activities = self.get_untracked_activities(ActivityState.TO_BE_PROCESSED)
        if _new_activities:
            LOG.info("Found new activities: %s", _new_activities)
        for activity_id, activity_file in _new_activities.items():
            _activity = TrackedActivity(activity_file)
            if _activity.type not in self.handled_activity_types:
                LOG.warning(
                    "Found activity of unhandled type %s: skipping", _activity.type
                )
            else:
                self.tracked_activities[activity_id] = _activity

        tbp_activity_files_by_type = Stream(
            self.get_tracked_activities(ActivityState.TO_BE_PROCESSED)
        ).collect(
            Collector.to_defaultdict(
                key_mapper=lambda ta: ta.type,
                value_mapper=lambda ta: ta.activity_file,
            )
        )

        for _type, _activity_files in tbp_activity_files_by_type.items():
            # Get available execution parallel instances
            available_execution_threads = self.allowed_parallel_processes(_type) - sum(
                1
                for x in self.get_tracked_activities(ActivityState.IN_PROGRESS)
                if x.type == _type
            )

            if available_execution_threads <= 0:
                continue

            # A subset of activities that can be launched immediately is selected ..
            will_process_now_count = min(
                len(_activity_files), available_execution_threads
            )
            will_process_now = _activity_files[:will_process_now_count]

            # .. and its execution is launched
            LOG.info(
                "Starting the processing of %s activities of type %s",
                will_process_now_count,
                _type,
            )
            proc = self.processor_by_handled_activity_type[_type]
            proc_exceptions = self.processor_runner.process_activities(
                arguments=[
                    {
                        "processor": proc,
                        "activity_dirs": self.activity_dirs,
                        "tracked_activity": self.tracked_activities[
                            Activity.get_id(f.name)
                        ],
                        "worker_id": self.worker_id,
                        "properties_manager_setup": self.properties_manager.source_files,
                    }
                    for f in will_process_now
                ],
                parallel_instances=will_process_now_count,
            )

            caught_exceptions: List[Exception]
            if caught_exceptions := [e for e in proc_exceptions if e is not None]:
                self.process_caught_exceptions(proc, caught_exceptions)

    def process_caught_exceptions(
        self, processor: Processor, caught_exceptions: List[str]
    ) -> None:
        """If setup correctly, caught processor runtime exceptions can be processed
        by creating new activities.
        Available macros are $ERROR_MSG, $FAILED_PROC
        """

        proc_name = processor.__qualname__  # type: ignore[attr-defined]

        on_exception_activity_content: str = self.properties_manager.get_string(
            self, self.ON_EXCEPTION_ACTIVITY_CONTENT_PPTY, required=True
        )

        self.create_activities(
            activity_type=PROCESSOR_ERROR_ID,
            activities_data=[
                on_exception_activity_content.replace(
                    "$ERROR_MSG", make_JSON_string_safe(ex)
                ).replace("$FAILED_PROC", proc_name)
                for ex in caught_exceptions
            ],
        )

    def setup_bootstraps(self) -> Callable[[Path], list[ActivityBootstrapRule]]:
        """Given bootstrap configuration, create activities in TO_BE_PROCESSED status"""

        _default_rows = [
            {
                LABEL_ACTIVITY_TYPE: BOOTSTRAP_ACTIVITIES_SPECIAL_ACTIVITY_TYPE,
                LABEL_WORKER_ID: self.worker_id,
                LABEL_BOOTSTRAP_RULE: "@every 5m",
            },
            # {
            #     LABEL_ACTIVITY_TYPE: ActivityArchivalProcessor.INPUT_ACTIVITY_TYPE,
            #     LABEL_WORKER_ID: self.worker_id,
            #     LABEL_BOOTSTRAP_RULE: "@every 24h",
            # },
        ]
        _handled_activity_types = self.handled_activity_types
        _worker_id = self.worker_id

        def inner(configuration_file: Path) -> list[ActivityBootstrapRule]:
            bootstrap_configuration = RuleEngine(
                configuration_file,
                columns=BOOTSTRAP_CONFIG_HEADER,
                default_rows=_default_rows,
                meta_header=ACTIVITY_BOOTSTRAP_META_HEADER,
            )

            def build_criteria(activity_type: str) -> dict:
                res = {LABEL_ACTIVITY_TYPE: activity_type}
                if _worker_id:
                    res[LABEL_WORKER_ID] = _worker_id
                return res

            # <activity_type>: [(<bootstrap_rule>, <activity_data>, <do_fire_on_first_cycle>)]
            bootstrap_data_by_type: dict[str, list[tuple[str, str, bool]]] = {}
            for _type in _handled_activity_types:
                try:
                    bootstrap_data_by_type[_type] = [
                        (
                            str(mapping[LABEL_BOOTSTRAP_RULE]),
                            str(mapping[LABEL_ACTIVITY_DATA]),
                            bool(mapping[LABEL_FIRE_ON_FIRST_CYCLE]),
                        )
                        for mapping in bootstrap_configuration.get_mappings(
                            build_criteria(_type),
                            values=[
                                LABEL_BOOTSTRAP_RULE,
                                LABEL_ACTIVITY_DATA,
                                LABEL_FIRE_ON_FIRST_CYCLE,
                            ],
                        )
                    ]
                except NoRuleMatchError:
                    LOG.info("Activity type %s has no bootstrap rule", _type)

            LOG.info(
                "Found bootstrap rule(s) for activity type(s) %s",
                ",".join(bootstrap_data_by_type.keys()),
            )
            activity_bootstrap_rules: list[ActivityBootstrapRule] = []
            for (
                _type,
                _bootstrap_rules,
            ) in bootstrap_data_by_type.items():
                for _bootstrap_data in _bootstrap_rules:
                    _bootstrap_rule, _activity_data, _fire_on_first_cycle = (
                        _bootstrap_data[0],
                        _bootstrap_data[1].replace(
                            "$PYPELINE_DIR", self.root_dir.as_posix()
                        ),
                        _bootstrap_data[2],
                    )
                    if not isinstance(_bootstrap_rule, str):
                        raise ValueError(
                            f"Expected bootstrapping rule to be a string, found {_bootstrap_rule} ({type(_bootstrap_rule)})"
                        )
                    activity_bootstrap_rules.append(
                        ActivityBootstrapRule(
                            _type, _bootstrap_rule, _activity_data, _fire_on_first_cycle
                        )
                    )

            return activity_bootstrap_rules

        return inner

    def setup_activity_processing_configuration(self) -> Callable[[Path], RuleEngine]:
        """Reads the activity processing configuration file and verifies all activities have a row"""

        _default_rows = [
            {
                LABEL_ACTIVITY_TYPE: BOOTSTRAP_ACTIVITIES_SPECIAL_ACTIVITY_TYPE,
                LABEL_WORKER_ID: self.worker_id,
                LABEL_PARELLEL_PROCESSES: "1",
            },
            {
                LABEL_ACTIVITY_TYPE: ActivityArchivalProcessor.INPUT_ACTIVITY_TYPE,
                LABEL_WORKER_ID: self.worker_id,
                LABEL_PARELLEL_PROCESSES: "1",
            },
        ]
        _handled_activity_types = self.handled_activity_types

        def inner(configuration_file: Path) -> RuleEngine:
            rule_engine = RuleEngine(
                configuration_file=configuration_file,
                columns=ACTIVITY_PROCESSING_CONFIG_HEADER,
                default_rows=_default_rows,
                meta_header=ACTIVITY_PROCESSING_META_HEADER,
            )

            for activity_type in _handled_activity_types:
                try:
                    rule_engine.get_single_mapping(
                        {LABEL_ACTIVITY_TYPE: activity_type}, LABEL_WORKER_ID
                    )
                except NoRuleMatchError as e:
                    raise NoRuleMatchError(
                        f"No rule in file {configuration_file} for activity {activity_type}"
                    ) from e

            return rule_engine

        return inner

    def do_bootstrap_activities(self, current_time: datetime) -> None:
        """Executes bootstrap rules at current time"""
        for _rule in self.activity_bootstrap_rules.get():
            try:
                new_activity = _rule.apply(current_time, self.tracked_activities.keys())
                LOG.debug("rule=%s new_activity=%s", _rule, new_activity)
                if new_activity is not None:
                    new_activity.write_file(self.root_dir)
            except Exception as e:
                LOG.exception(e)

    def resynchronize_tracked_activities(self) -> None:
        """Removes deleted items from tracked_activities"""
        self.tracked_activities = {
            ta_id: ta
            for ta_id, ta in self.tracked_activities.items()
            if ta.still_exists
        }
        if len(self.tracked_activities) > 2**10:
            LOG.warning(
                "Unusually high tracked activity count: %s",
                len(self.tracked_activities),
            )

    def run(self) -> None:
        """This is the main loop"""

        # self.timer_manager.add_timer(self.do_bootstrap_activities, 15)
        # self.timer_manager.add_timer(self.process_tbp_activities, 5)
        pm: PropertiesManager = PropertiesManager.get_instance()
        sleep_time = pm.get_int(self, self.SLEEP_SECONDS_PPTY, default=10)

        while True:
            current_time = datetime.now()
            LOG.info("Orchestrator run")

            if pm.get_bool(self, self.STOP_NOW_PPTY, default=False):
                LOG.info("Shutting down now")
                return

            # bootstrap activities
            self.do_bootstrap_activities(current_time)

            # process activities
            try:
                self.process_tbp_activities()
            except Exception as e:
                LOG.exception(e)

            self.resynchronize_tracked_activities()

            # sleep until next cycle
            time.sleep(sleep_time)
